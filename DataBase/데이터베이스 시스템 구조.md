# 데이터베이스 시스템 구조

데이터베이스 시스템 구조는 하부 컴퓨터 시스템, 특히 프로세서 및 메모리 구조, 네트워크, 병렬 및 분산 처리와 같은 요소에 크게 영향을 받는다.

---

<br>

## 1. 개요

- 중앙집중 데이터베이스 시스템 : 멀티 태스킹을 지원하는 단일 장치에서 동작하도록 설계, 메가바이트 ~ 수백 기가바이트에 달하는 크기의 데이터베이스
- 병렬 데이터베이스 시스템 : 1980년대 후반 많은 장치에서 작업을 병렬적으로 수행하기 위해 개발
  - 중앙집중에 비하여 트랜잭션 처리 성능, 의사결정 지원 질의 처리 시간 및 저장 장치 용량 측면에서 우위를 가짐
  - 수백대의 장치가 병렬적으로 동작
  - 키를 통해 데이터를 저장하고 검색
  - 병렬 데이터베이스와 달리 시스템은 선언적 질의에 대한 지원이 매우 제한적
- 분산 데이터베이스 시스템 : 데이터가 서로 다른 데이터베이스 시스템에서 생성/저장되고, 여러 데이터베이스에서 질의를 실행하고 트랜잭션을 갱신하기 위해 등장
  - 고장 허용 기술로 대규모 병렬 데이터베이스 및 데이터 저장 장치 시스템의 높은 신뢰성과 가용성을 보장

<br>

## 2. 중앙집중 데이터베이스 시스템

- 단일 컴퓨터 시스템에서 동작하는 데이터베이스 시스템이다.
- 모바일 기기나 개인용 컴퓨터에서 동작하는 단일 사용자 데이터베이스 시스템에서부터 멀티 코어, 복수 개의 디스크 및 큰 크기의 메모리를 가진 서버에서 동작하는 고성능 데이터베이스 시스템까지 다양한 범위가 존재한다.
- 사용되는 방식에 따른 구분
  - 단일 사용자 시스템 : 프로세서 하나만 있고 동시에 하나 또는 두개의 디스크를 가지는 단일 사용자만 쓰는 시스템
    - 내장 데이터베이스 : 응용 프로그램 내부에 포함된 형태의 데이터베이스 시스템. SQL대신 API로 데이터 접근, 낮은 동시성 제어 기법, 데이터 복구 방법이 초보적
  - 다중 사용자 시스템 : 더 많은 디스크와 더 많은 메모리로 구성, 멀티 프로세서를 가질 수 있다. 원격으로 시스템에 연결된 많은 사용자에게 서비스 제공(= 서버 시스템)
    - 서버로 설계
    - 트랜잭션에 대한 다양한 기능
- 굵은 단위 병렬화 : 적은 개수의 코어(1~4)와 공유 메모리 사용하는 병렬화
  - 모든 프로세서가 메인 메모리 공유
  - 하나의 질의를 여러 프로세서에 분할하지 않음, 각 질의를 각 프로세서에서 수행
  - 개별 트랜잭션 속도는 느리나, 초당 트랜잭션 처리 속도는 빠름
- 미세 단위 병렬화 :
  - 많은 수의 프로세서 보유
  - 단일 작업도 병렬화함

<br>

## 3. 서버 시스템 구조

- 트랜잭션 서버(= 질의 서버) : 
  - 클라이언트가 동작을 수행하기 위한 요청을 보냄
  - 요청에 대한 응답으로 시스템이 동작을 수행하고 결과를 클라이언트에게 보낸다.
  - 서버는 트랜잭션 처리 로직을 담당
- 데이터 서버 :
  - 클라이언트가 파일이나 페이지와 같은 단위로 데이터를 읽거나 갱신하는 요청을 함으로써 서버와 접속하는 시스템
  - 서버는 데이터의 저장과 입출력을 담당
  - 인덱스 기능 제공
  - 트랜잭션을 통해 클라이언트 장치나 프로세스가 고장 난 경우에도 데이터가 일관성을 유지하도록 한다.

<br>

### 3-1. 트랜잭션 서버 구조
- 트랜잭션 서버 시스템은 공유 메모리에 접근하는 다중 프로세스로 구성된다.
- 데이터베이스 시스템을 구성하는 프로세스
  - 서버 프로세스 (Server Process)
    - 클라이언트의 요청을 직접 받아 SQL 명령 실행
    - SQL 또는 JDBC, ODBC와 같은 규약을 통해서 서버 프로세스에 전달
    - 몇몇 시스템은 모든 사용자 세션을 위해 단일 데이터베이스 프로세스를 사용하는 대신 여러 질의가 동시에 수행될 수 있도록 다중 스레드를 갖는다.
    - 프로세스가 다중 스레드를 동작시키는 하이브리드 구조를 갖는다.
  - 잠금 관리자 프로세스 (Lock Manager Process)
    - 동시성 제어를 위해 자원(데이터 항목)에 대한 잠금(Lock)을 관리
    - 잠금부여, 잠금 해제, 교착 상태 탐지
  - 데이터베이스 쓰기 프로세스 (Database Writer Process)
    - 변경된 버퍼 블록을 지속적으로 디스크에 기록
  - 로그 쓰기 프로세스 (Log Writer Process)
    - 로그 레코드 버퍼에 있는 로그 레코드를 안정 저장 장치로 출력
    - 공유 메모리에 있는 로그 레코드 버퍼에 단순히 추가하는 일만 수행
    - 로그 강제 필요시 로그 레코드를 출력하도록 요청
  - 검사점 프로세스 (Checkpoint Process) : 주기적으로 검사점 수행
    - 주기적으로 모든 변경 내용을 디스크에 반영하고, 로그의 복구 지점을 설정
  - 프로세스 감시 프로세스 (Process Monitor)
    - 각 서버 프로세스들을 감시하고 비정상 종료를 감지
    - 실패한 프로세스에 대한 복구나 정리 작업을 수행
- 공유 메모리가 공유하는 것
  - 버퍼 풀
  - 잠금 테이블
  - 안정 저장 장치의 로그로 출력되길 기다리는 로그 레코드를 담고 있는 로그 버퍼
  - 같은 질의가 다시 요청될 경우 재사용되는 캐시된 질의 계획
- 상호 배제 (Mutual Exclusion)
  - 여러 트랜잭션이 동시에 같은 자원을 변경하지 못하도록 하나의 트랜잭션만 접근 허용
- 원자적 명령어 (Atomic Instruction)
  - 컴퓨터 하드웨어가 지원하는 명령어
  - Compare-and-Swap, Test-and-Set
- 잠금을 획득하고자 하는 트랜잭션의 단계
  1. 잠금 테이블의 뮤텍스(래치)를 획득
  2. 잠금을 할당할 수 있는지 확인
    - 할당 가능시 잠금 테이블 갱신
    - 불가능시 잠금 요청이 해당 자금 요청 큐에 있음을 나타내도로고 잠금 테이블 갱신
  3. 잠금 테이블의 뮤텍스를 해제
- 잠금 해제 과정 
  1. 잠금 테이블의 뮤텍스를 획득
  2. 잠금 테이블에서 해제할 잠금 항목을 삭제
  3. 현재 잠금에 할당할 수 잇는 데이터 항목에 대해 대기 중인 다른 잠금 요청이 있는 경우, 해당 잠금 요청이 할당되었음을 표시하도록 잠금 테이블 갱신
  4. 잠금 테이블의 뮤텍스를 해제
- 잠금 테이블에 대한 계속된 검사를 하지 않도록 잠금 요청 코드는 운영체제 세마포어를 사용하여 잠금 부여 알림을 기다릴 수 있다. 이 경우에는 잠금 해제 코드는 기다리는 트랜잭션에 잠금을 수여했음을 알리기 위한 세마포어 방법을 사용해야 한다.

<br>

### 3-2. 데이터 서버와 데이터 저장 장치 시스템
- 데이터 서버 시스템 : 객체 지향 데이터베이스에서 데이터 접근을 지원하기 위해 데이터 서버 시스템 개발
- 객체 지향 데이터베이스
  - 프로그래머가 영속 객체의 생성, 검색 및 갱신을 가능하게 하는 프로그래밍 언어를 사용할 수 있게 한다.
  - 컴퓨터 보조 설계(CAD) 시스템과 같이 검색한 데이터에 대해 광범위한 계산을 수행하는 응용 프로그램에 주로 사용
  - 데이터의 저장 및 가져오기 기능만 수행, 병렬 처리, 트랜잭션, 인덱싱, 최적화 등은 클라이언트 측에서 처리
- 이전 세대에서는 페이지 전달이라는 개념을 지원했으나 이제는 사용하지 않는다. 클라이언틑에게 저장 장치 시스템이 하부 저장 배치 구조를 노출하지 않기 때문

<br>

### 3-3. 클라이언트의 캐싱
- 클라이언트와 서버간의 통신시간은 지역 메모리 참조에 드는 시간보다 항상 크다.
- 네트워크 왕복시간 : 클라이언트가 요청을 보내고 서버가 응답을 돌려줄 때까지 걸리는 총 시간
- 네트워크 대기 시간 : 요청이나 응답이 한 방향으로 이동하는 데 걸리는 시간
- 네트워크 대기 시간 최적화 전략
  - 미리 가져오기 (Prefetching): 클라이언트가 앞으로 필요할 가능성이 있는 데이터를 미리 요청해 저장
  - 데이터 캐싱 (Data Caching) : 조회된 데이터 페이지나 항목을 클라이언트 측 로컬에 저장
    - 캐시 일관성 문제 발생 가능 :  데이터가 최신 상태임을 보장해야함
    - 캐시 무효화 정책 필요 (변경된 데이터 반영 문제)
  - 잠금 캐싱 (Lock Caching)
    - 자주 접근하는 데이터에 대한 잠금 정보를 클라이언트 측에 저장
    - 클라이언트가 잠금 요청을 생략하거나 더 빠르게 처리 가능
    - 서버와 클라이언트의 잠금 일관성을 유지를 위한 동기화 메커니즘 필요
  - 적응형 잠금 단위 (Adaptive Lock Granularity) : 상황에 따라 잠금의 단위를 조정(데이터량이 적을 땐 페이지 수준, 많을 땐 테이블 수준)
  - 잠금 축소 (Lock De-escalation) : 트랜잭션이 모든 잠금이 아닌 필요한 최소한만 유지

<br>

## 4. 병렬 시스템

- 여러 대의 컴퓨터를 병렬로 사용하여 처리와 I/O 속도를 향상시킨다.
- 굵은 단위 병렬 : 소수의 강력한 프로세서로 구성
- 미세 단위 병렬(=대규모 병렬) : 수천 개의 더 작은 프로세서 사용
- 대규모 병렬 컴퓨터는 일반적으로 많은 수의 컴퓨터로 구성된다. 여기서 각 컴퓨터는 노드로 불린다.

<br>

### 4-1. 병렬 데이터베이스의 필요성
- 병렬 데이터베이스 등장 이유
  - 매우 큰 데이터베이스(페타바이트 단위)에 대해 질의
  - 초당 많은 수의 트랜잭션을 처리해야하는 수요
- 의사결정 지원 질의 (Decision Support Query)
  - 비즈니스 인텔리전스, 데이터 분석, 경영 전략 수립 등에 활용되는 복잡한 분석 쿼리
  - 일반적으로 수백 TB 이상의 테이블을 대상으로 많은 연산을 필요로 하며, 병렬 처리 없이는 비효율적

<br>

### 4-2. 병렬 시스템의 성능 평가 요소
- 평가 요소:
  - 처리량 (Throughput) : 단위 시간당 처리할 수 있는 작업량
  - 응답시간 (Response Time) : 작업 하나를 처리하는 데 걸리는 시간
- 병렬화를 연구하는 데 두 가지 중요한 쟁점:
  - 속도 향상 (Speedup) : 병렬화의 단위를 증가시켜서 더 적은 시간 동안에 작업을 수행하는 것
    - 선형 속도 향상 (Linear Speedup) : 프로세서 수를 N배로 늘렸을 때 속도도 정확히 N배 빨라지는 것
    - 선형보다 낮은 속도 향상 (Sub-linear Speedup) : 병렬화했지만, 속도 증가가 비례하지 않음
  - 규모 증대 (Scaleup) : 병렬화의 단위를 증가시켜서 더 많은 수의 작업을 처리하는 것
    - 선형 규모 증대 (Linear Scaleup) : 데이터와 자원을 동시에 늘렸을 때, 성능이 그대로 유지되는 이상적 상황
    - 선형보다 낮은 규모 증대 (Sub-linear Scaleup) : 데이터 증가량보다 시스템 성능 증가가 부족한 경우
    - 배치 규모 증대 (Batch Scaleup) : 일괄 작업(batch job)의 수나 크기를 늘렸을 때, 병렬 시스템이 그 증가분을 실행 시간 증가 없이 효율적으로 감당할 수 있는지를 평가하는 지표
    - 트랜잭션 규모 증대 (Transaction Scaleup) : 동시에 발생하는 트랜잭션 수가 증가했을 때, 병렬 시스템이 그 부하를 응답 시간 악화 없이 처리할 수 있는지 평가하는 지표
- 병렬 처리의 실제 고려 요소
  - 초기 가동 비용 (Startup Cost) : 병렬 작업을 시작하기 위한 스레드 생성, 데이터 분할, 통신 설정 등의 오버헤드, 작은 작업에서는 병렬화가 오히려 손해
  - 간섭 (Interference) : 여러 프로세스 간 자원 경쟁으로 인해 발생하는 성능 저하
  - 치우침 (Skew) : 데이터 분배 또는 작업 분배가 불균형하여 일부 노드에 부하 집중

<br>

### 4-3. 상호 연결 네트워크
- 프로세서, 메모리, 저장장치, 노드 등을 연결하여 데이터 통신이 가능하도록 해주는 구조
- 네트워크 토폴로지 종류(구조 기반)
  - 버스(Bus)
    - 모든 노드가 하나의 공용 전송선로에 연결된 구조
    - 장점: 구조 단순, 비용 저렴
    - 단점: 충돌, 확장성, 대역폭 제한
  - 고리(Ring)
    - 노드가 원형으로 연결, 각 노드가 이웃 노드와만 통신
    - 장점: 구조 간단
    - 단점: 한 노드 문제 시 전체 영향, 지연 증가
  - 메시(Mesh)
    - 노드들이 2차원 또는 다차원 격자 형태로 연결
    - 장점: 확장 용이, 이웃 간 빠른 통신
    - 단점: 데이터 전송에 필요한 홉 수가 노드 수에 따라 매우 증가, 병렬 시스템에는 적합하지 않음
  - 하이퍼 큐브(Hypercube)
    - 2ⁿ개의 노드를 n차원 큐브 형태로 연결, 각 노드는 n개의 노드와 연결됨
    - 장점: 짧은 평균 거리, 높은 연결성
  - 트리형 구조(Tree-like)
    - 데이터 센터의 서버 시스템은 일반적으로 렉에 장착되며, 각 랙은 최대 40개의 노드를 수용한다.
    - 엣지 스위치(Edge Switch) : 랙과 직접 연결
    - 집계 스위치 : 엣지 스위치와 코어 스위치 중간 단계
    - 코어 스위치(Core Switch) : 모든 집계 스위치가 연결된다.
    - 팻-트리 토폴로지(Fat-Tree Topology) : 트리 구조에서 상위 계층으로 갈수록 링크 대역폭을 넓게 설계
      - 병목 완화, 트래픽 부하 분산
      - 적절한 라우팅 알고리즘 사용시 몇개의 스위치 장애에도 정상 작동이 가능하다.
    - 트리형 구조는 수만 대 장치의 클러스터를 다룰수 있다.
    -  데이터 센터 패브릭(Data Center Fabric) : 트리형 또는 팻-트리형 구조를 기반으로 한 대규모 네트워크 아키텍처
- 네트워크 기술
  - 이더넷(Ethernet) : 가장 널리 사용되는 네트워크 기술
    - 최신 버전은 40GbE, 100GbE 이상 가능
    - 근거리는 구리 케이블, 장거리는 광섬유 사용
  - 파이버 채널(Fibre Channel) : 저장 장치 시스템과 컴퓨터 간의 고속 상호 연결을 위해 설계
    - 고속 스토리지 네트워크(SAN)에 사용
  - 인피니밴드(InfiniBand) : 데이터 센터와 상호 연결을 위해 설계, 매우 높은 대역폭과 매우 낮은 지연 시간
- 대기 시간 줄이는 방법 :
  - 운영체제 우회
  - 원격 직접 메모리 접근(RDMA: Remote Direct Memory Access)
    - CPU 개입 없이 한 노드의 메모리를 다른 노드가 직접 접근할 수 있도록 함
    - 인피니밴드, RoCE(RDMA over Converged Ethernet) 등에서 사용

<br>

### 4-4. 병렬 데이터베이스 구조
- 공유 메모리 : 모든 프로세서가 공통의 메모리를 공유한다.
- 공유 디스크(= 클러스터) : 노드의 집합은 공통의 디스크 집합을 공유한다.
- 비공유 : 공통의 메모리나 디스크를 전혀 공유하지 않는 노드들의 집합
- 계층형 : 세 가지 구조의 하이브리드

<br>

### 4-5. 공유 메모리
- 공유 메모리 구조는 모든 프로세서가 하나의 메모리 공간을 공유하면서 동시에 접근하며 디스크도 공유한다.
- 빠른 내부 통신과 단일 시스템 관리의 이점

<br>

#### 4-5-1. 공유 메모리
- 과거에는 버스를 통해 메모리가 연결되었다. 그 결과 프로세서를 추가해도 병목 현상으로 인하여 속도 및 처리량에 변화가 없다.
- 불균열 메모리 구조 (NUMA: Non-Uniform Memory Access) : 자신에게 가까운 메모리 접근은 빠르고, 다른 CPU의 메모리에 접근할수록 느려짐
  - 캐시 미스 (Cache Miss) : CPU가 필요한 데이터를 캐시에서 찾지 못하고 메인 메모리까지 접근해야 하는 상황, 공유 메모리 구조에서는 여러 스레드가 같은 데이터에 접근하면서 캐시 미스 증가 가능
  - 하이퍼 스레딩 (Hyper-Threading) : 하나의 CPU 코어에서 두 개 이상의 스레드를 동시에 실행할 수 있게 하는 기술
- 캐시 라인 (Cache Line) : CPU 캐시에서 데이터를 저장하고 교환하는 최소 단위

<br>

#### 4-5-2. 캐시 일관성
- 캐시 일관성은 여러 개의 프로세서 또는 코어가 공유된 메모리 데이터를 각각 자신의 캐시에 저장할 때, 데이터가 항상 동일하게 보이도록 유지하는 메커니즘
- 복사본 무효화 : 한 프로세서가 공유된 데이터에 대한 값을 변경할 때, 다른 캐시에 존재하는 그 데이터의 복사본을 무효화
- 메모리 장벽 (Memory Barrier) : 하드웨어나 컴파일러가 메모리 연산의 순서를 바꾸지 못하도록 강제하는 명령어
- 저장 장벽 (Store Barrier) : 장벽 앞의 모든 write(저장) 연산이 메모리에 완전히 반영된 후에만, 그 뒤의 write 연산이 실행되도록 보장
- 적재 장벽 (Load Barrier) : 장벽 뒤의 모든 read(적재) 연산이, 장벽 앞의 read 연산이 완료된 후에만 실행되도록 보장
- 메모리 장벽은 병렬 환경에서 명령어 순서를 강제하여 일관성과 동기화 문제를 방지하는 필수 개념이다.
- MESI 프로토콜 : 멀티코어 또는 멀티프로세서 환경에서, 각 코어의 캐시 간 데이터 일관성(Cache Coherency)을 유지하기 위해 사용되는 하드웨어 기반 캐시 일관성 프로토콜
  - M (Modified) :	해당 캐시 라인은 변경되었고, 메인 메모리와 불일치함. → 캐시에만 최신 데이터 있음
  - E (Exclusive)	: 해당 데이터는 캐시에만 존재하지만, 메모리와 내용이 같음 (아직 수정되지 않음)
  - S (Shared) : 여러 캐시에 복사본이 존재하며, 메모리와도 일치
  - I (Invalid)	: 캐시 라인이 무효화되어, 더 이상 사용 불가한 상태
  - 쓰기 시에는 다른 캐시 복사본을 무효화하여 데이터 충돌을 방지하며, 효율적인 상태 전이를 통해 메모리 접근을 줄이고 병렬 시스템의 일관성을 보장

<br>

### 4-6. 공유 디스크
- 각 노드에는 자체 프로세서와 메모리가 있지만, 모든 노드는 상호 연결 네트워크를 통해 모든 디스크에 직접 접근할 수 있다.
- 여러 DB 서버(노드)가 공동으로 하나의 저장 장치(디스크)를 공유하면서, 각각 독립적인 메모리와 프로세서를 갖는 병렬 데이터베이스 구조
- 공유 메모리대비 장점 :
  - 더 많은 수의 프로세서로 확장할 수 있다.
  - 고장 허용을 싼값에 제공 가능
    - 어떤 노드가 고장나도, 디스크에 접근 가능한 다른 노드가 즉시 복구 가능
- RAID 구조를 사용하여 장애 허용하게 할 수 있다.
- SAN : 고속 전용 스토리지 네트워크 인프라
  - 여러 서버가 블록 단위로 디스크에 접근 가능
  - 높은 대역폭, 낮은 지연, 다수 노드 접근 지원
  - 병렬 DBMS에서 SAN을 통해 모든 노드가 하나의 디스크 시스템에 접속함

<br>

### 4-7. 비공유
- 각 노드가 CPU, 메모리, 디스크 등 모든 자원을 독립적으로 소유하고, 다른 노드와 자원을 공유하지 않는 병렬 데이터베이스 구조.
- 노드들은 고속 상호 연결 네트워크를 통해 서로 통신한다.
  - 장점 : 
    - 우수한 확장성 (Scale-out) : 노드를 추가하면 성능도 거의 선형적으로 증가
    - 장애 격리 가능 : 한 노드가 실패해도 전체 시스템에는 영향 제한
    - 저렴한 하드웨어 구성 가능
  - 단점 : 
    - 쿼리 분산 처리 복잡 (특히 Join, Aggregation)
    - 데이터 재분배 비용 큼 (리밸런싱 어려움)
    - 노드 간 통신 지연 발생 가능

<br>

### 4-8. 계층형 시스템
- 여러 수준의 처리 노드들이 계층적으로 구성되어 있는 데이터베이스 시스템 아키텍처.
- 상위 노드가 하위 노드들을 통제하거나 요청을 분배
- 하드웨어 계층이나 네트워크 구조를 반영한 설계
- 상위에는 비공유 구조, 중간은 공유 디스크 구조로 연결된 계층형으로 시스템 구성

<br>

## 5. 분산 시스템

- 분산 데이터베이스 시스템은 데이터베이스가 물리적으로 여러 장소에 나뉘어 저장되어 있지만, 사용자에게는 하나의 통합된 데이터베이스처럼 보이도록 작동하는 시스템이다.
- 데이터 분산 저장: 노드마다 일부 데이터 저장
- 논리적 통합: 사용자 입장에서는 단일 DB처럼 사용
- 분산 DB vs 비공유 병렬 DB
  - 사이트 차이 : 분산 DB는 자치성(autonomy) 강조, 비공유 병렬 DB는 중앙 집중 제어
    - 분산 데이터베이스	: 각 노드는 자율적인 DBMS 인스턴스를 독립적으로 운영함 (운영 정책, 사용자 관리도 개별 가능)
    - 비공유 병렬 데이터베이스 : 하나의 논리적 DB 인스턴스로 운영 → 노드는 완전히 중앙에서 제어됨
  - 노드 장애 문제 : 분산 DB는 장애 격리성이 뛰어나고, 병렬 DB는 복원력이 아키텍처에 따라 다름
    - 분산 데이터베이스	: 일부 노드 장애 시 해당 지역 기능만 중단, 나머지는 정상 운영
    - 비공유 병렬 데이터베이스 : 하나의 노드라도 실패하면 전체 시스템 성능 혹은 작업 자체에 영향 가능
  - 개별적 관리 : 분산 DB는 유연하지만 관리 복잡, 병렬 DB는 통합 관리가 용이
    - 분산 데이터베이스	: 각 노드의 스키마, 사용자, 보안 설정, 소프트웨어 버전도 독립적일 수 있음	
    - 비공유 병렬 데이터베이스 : 모든 노드가 동일한 설정과 버전으로 중앙에서 관리됨
  - 노드의 크기와 기능의 다양성 : 분산 DB는 이질적 환경을 수용 가능, 병렬 DB는 균질성 기반으로 최적화
    - 분산 데이터베이스	: 각 노드의 스키마, 사용자, 보안 설정, 소프트웨어 버전도 독립적일 수 있음	
    - 비공유 병렬 데이터베이스 : 모든 노드는 균등한 성능과 역할을 전제로 설계됨 (로드 밸런싱, 파티셔닝에 필요)
  - 지역 트랜잭션 : 분산 DB는 지역 트랜잭션 최적화 가능, 병렬 DB는 전역 병렬 처리에 집중
    - 로컬 노드에서 발생하고 로컬 데이터만 사용하는 트랜잭션 존재 가능 → 빠르고 단순	
    - 대부분의 쿼리는 병렬 처리를 위해 노드 간 데이터 접근 전제 → 트랜잭션은 전역적(그렇지 않으면 병렬 의미 약해짐)
- 분산 데이터베이스 특징 :
  - 데이터 공유 : 분산 데이터베이스 시스템에서 여러 사이트(노드)가 데이터 일부를 서로 공유하거나 복제하여 사용할 수 있는 능력.
  - 자치성 : 분산 시스템 내의 각 사이트(노드)는 자신의 데이터, 스키마, 트랜잭션 처리 등을 독립적으로 운영할 수 있는 능력을 의미함.
- 동종 분산 데이터베이스 (Homogeneous Distributed DB) : 모든 노드가 동일한 DBMS 소프트웨어와 동일한 데이터 모델, 스키마 형식을 사용하는 분산 데이터베이스 시스템
  - 중앙 통제가 가능하고, 각 노드 간 데이터 이동과 쿼리 처리 통일성 높음
- 연합 데이터베이스 시스템 (Federated Database System) : 서로 다른 종류의 데이터베이스 시스템(DBMS)이 자율적으로 운영되지만, 전체적으로는 하나의 논리적 데이터베이스처럼 작동하도록 구성한 시스템
  - 광역 네트워크를 통해 통신, 지연시간 존재, 네트워크 분할의 문제 발생 가능

<br>

## 6. 병렬 및 분산 시스템의 트랜잭션 처리

- 병렬 및 분산 시스템에서는 트랜잭션이 여러 노드에 걸쳐 동시에 실행될 수 있으며 이러한 경우에 트랜잭션의 원자성은 주요 문제로 대두된다.
- 2단계 커밋 규약 (Two-Phase Commit, 2PC) : 2PC는 분산 트랜잭션에서 여러 노드의 작업을 원자적으로 커밋하기 위한 표준적인 프로토콜
  - 1단계: 준비(Prepare/ Voting)
    - 코디네이터가 참여 노드(Participant)에게 "준비됐는가?" 메시지를 보냄
    - 각 노드는 자신의 트랜잭션을 로컬에 로그로 기록한 후 "예(YES)" 또는 "아니오(NO)"로 응답
  - 2단계: 커밋 또는 롤백(Commit/Abort)
    - 모두가 "YES" → 모두에게 커밋 명령
    - 하나라도 "NO" → 모두에게 롤백 명령
  - 트랜잭션의 원자성은 보장되지만, 동시성 문제와 지연, 블로킹 문제가 중요한 단점
    - 동시성 문제를 해결하기 위해 : 워크플로 관리 시스템 (Workflow Management System), 영속 메시지 (persistent Message)를 사용

<br>

## 7. 클라우드 기반 서비스

- 서버의 구축, 유지에 큰 비용 발생 -> 클라우드 컴퓨팅 대두
- 클라우드 컴퓨팅 : 다른 회사가 관리하는 인프라상에서 기업의 응용 프로그램을 실행한다.

<br>

### 7-1. 클라우드 서비스 모델
- IaaS (Infrastructure as a Service) : 서비스로서 인프라
  - 클라우드 제공자가 가상화된 하드웨어 자원(서버, 저장소, 네트워크 등)을 서비스 형태로 제공하는 모델이다.
  - 사용자는 운영체제부터 애플리케이션까지 직접 설치하고 구성하며, 하드웨어 인프라 관리는 클라우드 제공자가 맡는다.
  - 장점 : 
    - 유연성/확장성: 자원을 필요에 따라 즉시 확장/축소 가능
    - 비용 절감: 초기 인프라 투자 없음 → 운영비(운용비) 중심 과금
    - 제어권 확보: OS, 미들웨어, 애플리케이션을 직접 선택 및 구성 가능
    - 자동화 및 관리 API 제공
  - 단점 : 
    - 시스템 구성 및 유지보수 책임은 사용자에게 있음
    - 보안, 백업, 패치 등도 사용자가 직접 관리해야 함
    - 전문적인 IT 인프라 지식이 필요
- PaaS (Platform as a Service) : 서비스로서 플랫폼
  - 클라우드 제공자가 애플리케이션 개발과 실행을 위한 플랫폼(환경)을 서비스로 제공하는 모델이다.
  - 개발자는 서버, 운영체제, 미들웨어, 런타임 환경을 직접 설치하거나 관리할 필요 없이, 애플리케이션 코드에만 집중할 수 있다.
  - 클라우드 기반 데이터 저장 : PaaS에서 데이터 저장소(데이터베이스, 파일 스토리지 등)도 클라우드 기반으로 함께 제공하거나 연동할 수 있다.
    - 데이터베이스 서버를 직접 설치하거나 운영하지 않고, 필요한 저장소를 API로 호출하거나 콘솔에서 연결한다.
    - 일정 비용 지급 시 서비스를 운행하는 컴퓨터 시스템의 구매, 유지 관리에 대한 걱정없이 사용 가능
  - 서비스로서의 데이터베이스(Database as a Service) : 
    - 클라우드에서 데이터베이스를 서비스 형태로 제공하는 모델로, 인프라 설치, 설정, 백업, 보안, 패치 작업 등을 클라우드 제공자가 자동으로 관리한다.
- SaaS (Software as a Service) : 서비스로서 소프트웨어
  - 클라우드 제공자가 완성된 소프트웨어를 인터넷을 통해 사용자에게 제공하는 서비스 모델
  - 사용자는 설치, 유지보수, 업데이트 등을 신경 쓸 필요 없이, 웹 브라우저나 앱을 통해 서비스를 이용하면 된다.
- 가상머신(Virtual Machine, VM) : 가상머신은 하드웨어 자원을 소프트웨어로 가상화하여 만든 컴퓨터 환경
- 컨테이너(Container) : 애플리케이션과 그 실행 환경(라이브러리, 설정 등)을 하나의 패키지로 묶은 가볍고 빠른 실행 단위
  - 도커(Docker)가 대표적인 컨테이너 플랫폼
  - 하이퍼바이저 없이 커널 공유 → 실행 속도 빠름, 자원 소비 적음

<br>

### 7-2. 클라우드 서비스의 이점과 한계점
- 이점
  1. 비용 절감 : 서버, 스토리지 등 초기 인프라 구축 비용 없음. → 운영비(운용비) 기반 과금(pay-as-you-go)
  2. 확장성(Scalability) : 사용량 증가 시 자동 또는 수동으로 자원 확장 가능 (수평/수직 확장)
- 한계점
  1. 벤더 종속성(Vendor Lock-in) : 특정 클라우드 플랫폼에 기술, API, 데이터 포맷 등이 묶일 위험 존재
  2. 보안/개인정보 우려 : 민감한 데이터가 외부 서버에 저장됨 → 데이터 주권(Data Sovereignty) 이슈 발생 가능
