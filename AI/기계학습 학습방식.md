<details>
  
<summary>
  <strong>지도학습(Supervised Learning)과 비지도학습(Unsupervised Learning)의 차이를 설명하고, 각각의 대표적인 알고리즘을 하나씩 예를 들어 설명해주세요.</strong>
</summary>

<br>

1. **지도학습(Supervised Learning)**  
   - 입력 데이터(특징)와 정답(레이블)이 주어진 상태에서 모델을 학습하는 방식
   - 회귀(Linear Regression) : 주어진 입력으로부터 연속적인 값을 예측하는 알고리즘
   - 의사결정나무(Decision Tree) : 분류 또는 회귀를 수행하는 트리 기반 모델

2. **비지도학습(Unsupervised Learning)**  
   - 정답(레이블) 없이 데이터를 스스로 분석하여 패턴을 찾아내는 방식
   - K-Means Clustering : 데이터를 군집화(클러스터링)하여 유사한 그룹을 찾는 알고리즘
   - PCA(Principal Component Analysis) : 차원 축소 기법으로, 데이터의 중요한 특성을 유지하면서 차원을 줄이는 알고리즘
   
<br>
</details>
  
<br>

<details>
  
<summary>
  <strong>지도학습과 강화학습(Reinforcement Learning)의 차이를 설명하고, 강화학습에서 사용되는 주요 개념(RL의 핵심 요소)에 대해 설명해주세요</strong>
</summary>

<br>

1. **지도학습**  
   - 정답이 있는 데이터를 기반으로 모델이 학습하는 방식
   - 예시 : 이미지 분류, 음성 인식

2. **강화학습(Reinforcement Learning, RL)**  
   - 환경과의 상호작용을 통해 보상을 최대화하는 방향으로 학습하는 방식
   - 예시 : 알파고(AlphaGo), 로봇 제어, 자율주행

3. **강화학습의 핵심 개념**
   - 에이전트(Agent) : 행동을 수행하는 주체
   - 환경(Environment) : 에이전트가 상호작용하는 대상
   - 상태(State, S) : 현재 에이전트가 처한 상황
   - 행동(Action, A) : 에이전트가 환경에서 취할 수 있는 행동
   - 보상(Reward, R) : 특정 행동을 수행한 결과로 얻는 값 (보상 또는 패널티)
   - 정책(Policy, π) : 특정 상태에서 행동을 선택하는 전략
   - 가치함수(Value Function) : 특정 상태에서 미래의 보상을 예측하는 함수

<br>
</details>
  
<br>
